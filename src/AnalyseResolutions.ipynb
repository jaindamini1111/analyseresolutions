{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AnalyseResolutions. Tuomo Toljamo (King's College London; DiXiT) at the Huygens ING (KNAW), 2016.\n",
    "#\n",
    "# This PhDWare code-sketch was part of a pilot exploring the use and usefulness of image data and visual information in\n",
    "# the digital opening of an archival series, the Resolutions of the States General 1576‒1796.\n",
    "#\n",
    "# DiXiT (Digital Scholarly Editions Initial Training Network) has been funded from the People Programme (Marie Curie Actions) \n",
    "# of the European Union's Seventh Framework Programme FP7/2007-2013/ under REA grant agreement n° 317436. \n",
    "\n",
    "import IPython.core.display as ipy\n",
    "import sys\n",
    "import os\n",
    "import traceback\n",
    "from SpreadLevel import SauvolaBinarise\n",
    "from ColumnLevel import *\n",
    "from DocumentImageAnalysis import *\n",
    "from DocumentImageUnderstanding import *  \n",
    "from XMLFactory import XMLDocument\n",
    "import Levers\n",
    "import HelperFunctions as fu\n",
    "from HelperFunctions import debug\n",
    "from TextProcessing import processDatelineText\n",
    "\n",
    "# For Jupyter to autoload modules and get new changes in before execution.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process():\n",
    "    isRotated = False\n",
    "    pagesOutList = []\n",
    "    columnsOutList = []\n",
    "    facsPage = fu.Page()\n",
    "    Levers.imageIter = 0\n",
    "\n",
    "    \n",
    "    # IMAGE-LEVEL: LOADING THE ORIGINAL\n",
    "    original = Facsimile(fu.loadImage(Levers.dir_in, Levers.fileName), 'original')\n",
    "    original.save(Levers.fileName.replace(\".jpg\", \"\"))\n",
    "    \n",
    "    \n",
    "    # IMAGE-LEVEL: ANALYSE INPUT - Let's check if the image is landscape as expected.\n",
    "    imgShape = original.getImage().shape\n",
    "    if (imgShape[0] > imgShape[1]):\n",
    "        document.flush()\n",
    "        print (\"Skipping this image. It's not a spread.\")\n",
    "        document.addElement(\"facs\", {\"src\":Levers.fileName})\n",
    "        document.addElement(\"note\", {\"type\":\"processing\"}, \"Image skipped (reason: not a two-page spread).\")\n",
    "        return\n",
    "\n",
    "\n",
    "    # SPREAD-LEVEL: BINARISE\n",
    "    if (Levers.kludgeWin32bit == True):\n",
    "        binarised = SauvolaBinariseQuadrants(original)\n",
    "    else:\n",
    "        binarised = SauvolaBinarise(original, 'gaussian')\n",
    "    \n",
    "    \n",
    "    # SPREAD-LEVEL: REMOVE SCAN BORDERS\n",
    "    remBorders = cropBorderShadows(binarised, 'remBorders')\n",
    "\n",
    "\n",
    "    # SPREAD-LEVEL: EXTRACT PAGES\n",
    "    pages = extractPages(remBorders)\n",
    "    pagesOutList = pages\n",
    "\n",
    "    for i in range(0, len(pages)):\n",
    "        nameString = Levers.fileName.replace(\".jpg\",\"\")+\"_page\" + str(i+1)\n",
    "        \n",
    "        \n",
    "        # PAGE-LEVEL: APPLY HORIZONTAL MASK\n",
    "        maskedPage = applyMask(pages[i], nameString+'_masked')\n",
    "\n",
    "\n",
    "        # PAGE-LEVEL: CLEAN BORDERS\n",
    "        maskedPage = cleanBorders(maskedPage)\n",
    "\n",
    "\n",
    "        # PAGE-LEVEL: ANALYSE SKEW DETECTION AREA\n",
    "        skewDetectionArea = analyseSkewDetectionArea(maskedPage)\n",
    "        if skewDetectionArea == None:\n",
    "            document.flush()\n",
    "            if i==0:\n",
    "                document.addElement(\"facs\", {\"src\":Levers.fileName})\n",
    "            document.addElement(\"pb\", {\"n\":Levers.fileName.replace(\".jpg\", \"\")+\"#page\"+str(i+1)})\n",
    "            document.addElement(\"note\", {\"type\":\"processing\"}, \"Page skipped (reason: not body text).\")\n",
    "            #print (\"Skew detection area analysed: Not body text.\")\n",
    "            pagesOutList[i] = None\n",
    "            continue  # Breaking for the next page.\n",
    "        \n",
    "        \n",
    "        # PAGE-LEVEL: DETECT SKEW BASED ON DIVIDER\n",
    "        \n",
    "        # Apply vertical mask to the horizontally masked image.\n",
    "        doubleMaskedPage = applyVerticalMask(maskedPage, 'doubleMaskedPage')\n",
    "        #fu.nbimage(doubleMaskedPage.getImage())\n",
    "        \n",
    "        # PAGE-LEVEL: FIND DIVIDER\n",
    "        dividerCC = findDividingLine(doubleMaskedPage)\n",
    "        clusterRend = renderFacsCC(doubleMaskedPage, dividerCC, 'renderedDivider', (0,0))\n",
    "        clusterRend.save()\n",
    "        #fu.nbimage(clusterRend.getImage())\n",
    "        divAngle = calculateDividerAngle(dividerCC)\n",
    "        #print(\"Detected div angle:\", divAngle)\n",
    "        \n",
    "        if divAngle==None:\n",
    "            # Let's detect skew according to the older, projection-profile -based method.\n",
    "            angle = detectSkew(maskedPage, skewDetectionArea)\n",
    "            #angle = 0\n",
    "        else:\n",
    "            angle = divAngle*(-1)\n",
    "        \n",
    "        if ( abs(angle) < 0.15):\n",
    "            # the angle is not significant, let's do nothing\n",
    "            angle=0\n",
    "        #print (\"angle\", angle)\n",
    "\n",
    "        \n",
    "        # PAGE-LEVEL: ROTATE IMAGE IF NEEDED\n",
    "        if (angle != 0):\n",
    "            nameString = nameString + \"_rot\" + str(angle)\n",
    "            rotatedMaskedPage = rotateImage(maskedPage, angle, nameString+'_rotatedMaskedPage')\n",
    "            rotatedPageImg = rotateImage(pages[i], angle, nameString+'_rotatedPageImg')\n",
    "            isRotated = True\n",
    "        else:\n",
    "            isRotated = False\n",
    "\n",
    "\n",
    "        # PAGE-LEVEL: FIND DATELINE\n",
    "        if (isRotated):\n",
    "            dateLine, datelineComponentList = findDateLine(rotatedMaskedPage, nameString+'_dateLine')\n",
    "        else:\n",
    "            dateLine, datelineComponentList = findDateLine(maskedPage, nameString+'_dateLine')\n",
    "        \n",
    "        if dateLine == None:\n",
    "            document.flush()\n",
    "            document.addElement(\"pb\", {\"n\":str(i+1)})\n",
    "            document.addElement(\"note\", {\"type\":\"processing\"}, \"Page skipped (reason: not recognised as body text).\")\n",
    "            print (\"A dateline was not found: this page is not part of Resolutions body. Skipping to next page.\")\n",
    "            pagesOutList[i] = None\n",
    "            continue  # Breaking for the next page.\n",
    "        \n",
    "        \n",
    "        # PAGE-LEVEL: FIND DATELINE COMPONENTS\n",
    "        dlistsorted = sortCCListHorizontally(datelineComponentList)\n",
    "        datelineComponentClusters = findDatelineClusters(dlistsorted)\n",
    "        if (isRotated):\n",
    "            dateLineClusters = renderFacsCCClusters(rotatedMaskedPage,datelineComponentClusters, nameString+'_dateLineClusters', (0,0))\n",
    "        else:\n",
    "            dateLineClusters = renderFacsCCClusters(maskedPage,datelineComponentClusters, nameString+'_dateLineClusters', (0,0))\n",
    "\n",
    "        if Levers.debugFlag:\n",
    "            dateLineClusters.save(Levers.fileName.replace(\".jpg\",\"\")+\"_page\"+str(i), \"datelinePile\")\n",
    "\n",
    "\n",
    "        # PAGE-LEVEL: ANALYSE DATELINE - CHECK CLUSTERING\n",
    "        if len(datelineComponentClusters) == 2:\n",
    "            print (\"According to dateline clustering, this page is part of the index. Skipping to next page.\")\n",
    "            document.flush()\n",
    "            if (i == 0):\n",
    "                #document.flush()\n",
    "                document.addElement(\"facs\", {\"src\":Levers.fileName})\n",
    "                \n",
    "            document.addElement(\"pb\", {\"n\":str(i+1)})\n",
    "            document.addElement(\"note\", {\"type\":\"processing\"}, Levers.fileName+\"#page\"+str(i+1)+\": Page skipped (reason: part of the index).\")\n",
    "            pagesOutList[i] = None\n",
    "            continue  # Breaking for the next page.\n",
    "        if len(datelineComponentClusters) < 2 or len(datelineComponentClusters) > 3:\n",
    "            document.flush()\n",
    "            document.addElement(\"pb\", {\"n\":str(i+1)})\n",
    "            document.addElement(\"note\", {\"type\":\"processing\"}, \"Page skipped (reason: not recognised as body text).\")\n",
    "            print (\"According to dateline clustering, this page is not Resolutions body. Skipping to next page.\")\n",
    "            pagesOutList[i] = None\n",
    "            continue  # Breaking for the next page.\n",
    "\n",
    "        print (\"A dateline was found. Continuing processing.\")\n",
    "        #continue\n",
    "        \n",
    "        # PAGE-LEVEL: OCR DATELINE\n",
    "        if (isRotated):\n",
    "            datelineUnmasked = unmaskFacsimile(rotatedPageImg, dateLine, \"unmaskedDateline\")\n",
    "            #fu.nbimage(datelineUnmasked.getImage())\n",
    "\n",
    "            saveTesseractImage(datelineUnmasked.getImage(), \"page\"+str(i+1)+\"_dateline\")\n",
    "            datelineText = Tesseract(\"page\"+str(i+1)+\"_dateline\", \"dateline\")\n",
    "            datelineText = processDatelineText(datelineText)\n",
    "            #print(datelineText)    \n",
    "        else:\n",
    "            datelineUnmasked = unmaskFacsimile(pages[i], dateLine, \"unmaskedDateline\")\n",
    "            #fu.nbimage(datelineUnmasked.getImage())\n",
    "\n",
    "            saveTesseractImage(datelineUnmasked.getImage(), \"page\"+str(i+1)+\"_dateline\")\n",
    "            datelineText = Tesseract(\"page\"+str(i+1)+\"_dateline\", \"dateline\")\n",
    "            datelineText = processDatelineText(datelineText)\n",
    "            #print(datelineText)  \n",
    "\n",
    "            \n",
    "        # PAGE-LEVEL: FIND DIVIDER AREA\n",
    "        if (isRotated):\n",
    "            columnDividerArea = spliceDividerArea(rotatedMaskedPage, dateLine, getCentreCluster(rotatedMaskedPage, datelineComponentClusters))\n",
    "        else:\n",
    "            columnDividerArea = spliceDividerArea(maskedPage, dateLine, getCentreCluster(maskedPage, datelineComponentClusters))\n",
    "\n",
    "\n",
    "        # PAGE-LEVEL: APPLY VERTICAL MASK TO DIVIDER AREA\n",
    "        maskedColumnDividerArea = applyVerticalMask(columnDividerArea, nameString+'_verticallyMaskedSplice')\n",
    "\n",
    "\n",
    "        # PAGE-LEVEL: FIND DIVIDER FROM THE MASKED AREA\n",
    "        dividerCC = findDividingLine(maskedColumnDividerArea)\n",
    "        if Levers.debugFlag:\n",
    "            clusterRend = renderFacsCC(maskedColumnDividerArea, dividerCC, nameString+'_renderedDivider', (0,0))\n",
    "\n",
    "            \n",
    "        # PAGE-LEVEL: ANALYSE DIVIDER\n",
    "        if (isRotated):\n",
    "            (columnMin, columnMax) = analyseDivider(dividerCC, rotatedMaskedPage, columnDividerArea)\n",
    "        else:\n",
    "            (columnMin, columnMax) = analyseDivider(dividerCC, maskedPage, columnDividerArea)\n",
    "\n",
    "            \n",
    "        # COLUMN-LEVEL: EXTRACT COLUMNS\n",
    "        if (isRotated):\n",
    "            cols, (rotatedPageImgProcessedLeft, rotatedPageImgProcessedRight) = extractColumns(rotatedMaskedPage, columnDividerArea, dividerCC, columnMin, columnMax, rotatedPageImg)\n",
    "        else:\n",
    "            cols, (pageImgProcessedLeft, pageImgProcessedRight) = extractColumns(maskedPage, columnDividerArea, dividerCC, columnMin, columnMax, pages[i])\n",
    "\n",
    "        for j in range(0, len(cols)):\n",
    "            nameString2 = nameString + \"_col\" + str(j+1)\n",
    "            \n",
    "            # Removing catchwords\n",
    "            if (j==1):\n",
    "                cols[j] = removeCatchwords(cols[j])\n",
    "                        \n",
    "            cleanedImage = dia.cleanBorders2(cols[j].getImage())\n",
    "            \n",
    "            \n",
    "            # COLUMN-LEVEL: FIND BORDER-MOST CONNECTED COMPONENTS IN COLUMN\n",
    "            leftMostCC = findBorderMostConnectedComponents(cleanedImage.copy(), 'left')\n",
    "            rightMostCC = findBorderMostConnectedComponents(cleanedImage.copy(), 'right')\n",
    "            bottomMostCC = findBorderMostConnectedComponents(cleanedImage.copy(), 'bottom')\n",
    "            l = [leftMostCC, rightMostCC, bottomMostCC]\n",
    "            if Levers.debugFlag:\n",
    "                borderClusters = renderFacsCCClusters(cols[j], l, nameString2+'_borderClusters', (0,0))\n",
    "\n",
    "\n",
    "            # COLUMN-LEVEL: REMOVE EXTRA WHITESPACE FROM COLUMNS\n",
    "            colImgCropped = removeExtraWhitespace(cols[j], j, leftMostCC, rightMostCC, bottomMostCC)\n",
    "\n",
    "\n",
    "            # COLUMN-LEVEL: FIND LARGE INITIAL CAPITALS\n",
    "            if (isRotated):\n",
    "                if (j==0):\n",
    "                    colImgUnmasked = unmaskFacsimile(rotatedPageImgProcessedLeft, colImgCropped, nameString2+\"_ImgCroppedUnmasked\")\n",
    "                if (j==1):\n",
    "                    colImgUnmasked = unmaskFacsimile(rotatedPageImgProcessedRight, colImgCropped, nameString2+\"_ImgCroppedUnmasked\")\n",
    "            else:\n",
    "                if (j==0):\n",
    "                    colImgUnmasked = unmaskFacsimile(pageImgProcessedLeft, colImgCropped, nameString2+\"_ImgCroppedUnmasked\")\n",
    "                if (j==1):\n",
    "                    colImgUnmasked = unmaskFacsimile(pageImgProcessedRight, colImgCropped, nameString2+\"_ImgCroppedUnmasked\")\n",
    "\n",
    "            initialCandidates = findInitialCapitalCandidates(colImgUnmasked)\n",
    "\n",
    "            initialCapitalCCList = []\n",
    "            for z in range(0, len(initialCandidates)):\n",
    "                initialCapitalCCList.append( initialCandidates[z].getInitialCC() )\n",
    "\n",
    "            renderInitialCandidates = renderFacsCCList(colImgUnmasked,initialCapitalCCList,nameString2+'_initialCapitalCandidates', (0,0))\n",
    "\n",
    "            \n",
    "            # COLUMN-LEVEL: FIND VERTICAL SPACE CANDIDATES\n",
    "            spaceCandidates = findVerticalSpaceCandidates(colImgUnmasked)\n",
    "            \n",
    "            \n",
    "            # COLUMN-LEVEL: FIND PHYSICAL SECTIONS\n",
    "            physicalSections,validatedInitials,validatedSpaces = segmentColumn(colImgUnmasked, initialCandidates, spaceCandidates,i,j)\n",
    "            \n",
    "            # render\n",
    "            validatedInitialsCCList = []\n",
    "            for t in range(0, len(validatedInitials)):\n",
    "                validatedInitialsCCList.append( validatedInitials[t].getInitialCC() )\n",
    "\n",
    "            renderValidatedInitials = renderFacsCCList(colImgUnmasked,validatedInitialsCCList,nameString2+'_validatedInitialCapitals', (0,0))\n",
    "            \n",
    "            physicalSections = analyseSections(physicalSections)\n",
    "\n",
    "            physicalSections = ocrSections(physicalSections)\n",
    "\n",
    "            elementQueue = buildElementQueue(physicalSections, i, j, datelineText[0])\n",
    "            \n",
    "            processQueue(elementQueue, i, j, document)\n",
    "\n",
    "            # note: render only after spaces have been validated.\n",
    "            renderSpacesAndInitials = renderSections(renderValidatedInitials, validatedSpaces, nameString2+'_renderValidatedSpaces', (127,0,0))\n",
    "            renderSpacesAndInitials.save(Levers.fileName.replace(\".jpg\",\"\")+\"_page\"+str(i+1)+\"_col\"+str(j+1))\n",
    "            columnsOutList.append(renderSpacesAndInitials)\n",
    "            \n",
    "            # error: column text not processed at this point, only when the XML is saved.\n",
    "            facsPage.addPhysSections(i*2+j, physicalSections)\n",
    "            \n",
    "\n",
    "    # VISUALISE THE PRODUCTS ON TOP OF THE ORIGINAL FACSIMILE\n",
    "    outputImage = None\n",
    "\n",
    "    for k in range(len(columnsOutList)):\n",
    "        if (k==0):\n",
    "            outputImage = overlayRegion(original.getImage(), columnsOutList[k])\n",
    "        else:\n",
    "            outputImage = overlayRegion(outputImage, columnsOutList[k])\n",
    "\n",
    "    if (outputImage is not None):\n",
    "        theEnd = Facsimile(outputImage, Levers.fileName.replace(\".jpg\",\"\")+\"_finishedProcessing\")\n",
    "        theEnd.save()\n",
    "        theEnd.save(Levers.fileName.replace(\".jpg\",\"\")+\"_finishedProcessing\", \"finishedProcessing\")\n",
    "        theEnd.save(Levers.fileName.replace(\".jpg\",\"\")+\"_finishedProcessing\")\n",
    "        \n",
    "        document.saveDocument(\"results/\"+(Levers.saveDir)+\"/\", \"document.xml\")\n",
    "        \n",
    "        \n",
    "        # GENERATING HTML TESTING PAGES\n",
    "        html = fu.HTMLTestingPage(\"results/\"+str(Levers.saveDir)+\"/testingPage.html\", Levers.fileName)\n",
    "        html.addOriginal(Levers.fileName.replace(\".jpg\", \"\")+\".png\")\n",
    "        for i in range (0, len(pagesOutList)):\n",
    "            if pagesOutList[i] != None:\n",
    "                j=0\n",
    "                facsPage.addColText(i*2+j, getColumnText(facsPage.getPhysSections(i*2+j)))                \n",
    "                html.addColumn(\"Page \" + str(i+1) + \", Col \" + str(j+1), Levers.fileName.replace(\".jpg\",\"\")+\"_\"+\"page\"+str(i+1)+\"_col\"+str(j+1)+\".png\", \n",
    "                               facsPage.getColText(i*2+j))\n",
    "                \n",
    "                j=1\n",
    "                facsPage.addColText(i*2+j, getColumnText(facsPage.getPhysSections(i*2+j)))\n",
    "                html.addColumn(\"Page \" + str(i+1) + \", Col \" + str(j+1), Levers.fileName.replace(\".jpg\",\"\")+\"_\"+\"page\"+str(i+1)+\"_col\"+str(j+1)+\".png\", \n",
    "                               facsPage.getColText(i*2+j))\n",
    "       \n",
    "        \n",
    "        html.addOriginal(Levers.fileName.replace(\".jpg\", \"\")+\"_finishedProcessing.png\")\n",
    "        html.close()\n",
    "       \n",
    "    \n",
    "# Main\n",
    "        \n",
    "Levers.dir_in = \"images/\"\n",
    "Levers.dir_out = \"results/\"\n",
    "Levers.file_ext = \"jpg\"\n",
    "\n",
    "fileList = fu.getFiles(Levers.dir_in, Levers.file_ext)\n",
    "\n",
    "# Let's create the XML document\n",
    "document = XMLDocument()\n",
    "\n",
    "for f in range(0, len(fileList)):\n",
    "    Levers.fileName = fileList[f]\n",
    "    Levers.saveDir = Levers.fileName.replace(\".jpg\", \"\")\n",
    "\n",
    "    debug(\"[\"+fileList[f]+\"]: \" + \"Starting to process \"+Levers.fileName+\".\")\n",
    "    print(\"Starting to process \"+Levers.fileName+\".\")\n",
    "    try:\n",
    "        process()\n",
    "    except Exception:\n",
    "        e = traceback.format_exc()\n",
    "        print (e)\n",
    "        document.flush()\n",
    "        debug(\"[\"+fileList[f]+\"]: \" + \"Failed to process \"+Levers.fileName+\".\")\n",
    "        document.addElement(\"note\", {\"type\":\"processing\"}, \"Failed to process \"+Levers.fileName+\".\")\n",
    "        \n",
    "    \n",
    "document.flush()\n",
    "document.saveDocument(\"results/\"+(Levers.saveDir)+\"/\", \"document.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
